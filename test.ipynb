{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/deformable_detr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "temp = {37: [[2, 0.710587203502655, False, 117], [2, 0.710587203502655, False, 118], [2, 0.8552080392837524, False, 123], [2, 0.8552080392837524, True, 124], [2, 0.8819786906242371, True, 103], [2, 0.8819786906242371, True, 104], [2, 0.9262967705726624, True, 43], [2, 0.9262967705726624, True, 44], [2, 0.9485719799995422, True, 113], [2, 0.9485719799995422, True, 114], [2, 1.0069825649261475, True, 107], [2, 1.0069825649261475, True, 108], [2, 1.0108802318572998, True, 39], [2, 1.0108802318572998, True, 40], [2, 1.048500418663025, True, 109], [2, 1.048500418663025, True, 110], [2, 1.0621336698532104, True, 99], [2, 1.0621336698532104, True, 100], [2, 1.1646535396575928, True, 97], [2, 1.1646535396575928, True, 98], [1, 1.1964150667190552, True, 45], [2, 1.1964150667190552, True, 46], [2, 1.2234257459640503, True, 105], [2, 1.2234257459640503, True, 106], [2, 1.276465892791748, True, 51], [2, 1.276465892791748, True, 52], [2, 1.3770601749420166, True, 111], [2, 1.3770601749420166, True, 112], [2, 1.4207924604415894, True, 125], [2, 1.4207924604415894, True, 126], [2, 1.457613468170166, True, 33], [2, 1.457613468170166, True, 34], [1, 1.4961259365081787, True, 101], [2, 1.4961259365081787, True, 102], [4, 1.1897366046905518, True, 159]], 50: [[2, 0.9775761961936951, True, 161], [2, 0.9775761961936951, True, 162], [2, 1.1105427742004395, True, 171], [3, 1.1105427742004395, True, 172], [3, 1.1648470163345337, True, 173], [2, 1.1648470163345337, True, 174], [5, 1.1897366046905518, True, 160], [5, 1.2224220037460327, True, 163], [2, 1.2224220037460327, True, 164], [4, 1.316786766052246, True, 169], [5, 1.316786766052246, True, 170], [4, 1.3542976379394531, True, 175], [2, 1.3542976379394531, True, 176], [5, 1.4068158864974976, True, 165], [5, 1.4068158864974976, True, 166], [2, 1.483826756477356, True, 167], [3, 1.483826756477356, True, 168], [5, 1.4191384315490723, True, 177]], 58: [[2, 1.1466126441955566, True, 193], [2, 1.4191384315490723, True, 178], [2, 1.4333014488220215, True, 179], [4, 1.4333014488220215, True, 180], [4, 1.1466126441955566, False, 194]]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10770\n",
      "2677\n"
     ]
    }
   ],
   "source": [
    "load_dir0 = \"/data/LG/real_dataset/total_dataset/test_dir/Continaul_DETR/Rehearsal_dict/\" + str(0) + \"_gpu_rehearsal\" + \"_task_\" + str(0) + \"_ep_0\"\n",
    "load_dir1 = \"/data/LG/real_dataset/total_dataset/test_dir/Continaul_DETR/Rehearsal_dict/\" + str(1) + \"_gpu_rehearsal\" + \"_task_\" + str(0) + \"_ep_0\"\n",
    "load_dir2 = \"/data/LG/real_dataset/total_dataset/test_dir/Continaul_DETR/Rehearsal_dict/\" + str(2) + \"_gpu_rehearsal\" + \"_task_\" + str(0) + \"_ep_0\"\n",
    "load_dir3 = \"/data/LG/real_dataset/total_dataset/test_dir/Continaul_DETR/Rehearsal_dict/\" + str(3) + \"_gpu_rehearsal\" + \"_task_\" + str(0) + \"_ep_0\"\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "with open(load_dir0, 'rb') as f :\n",
    "    rehearsal_classes = pickle.load(f)\n",
    "        \n",
    "with open(load_dir1, 'rb') as f :\n",
    "    rehearsal_classes1 = pickle.load(f)\n",
    "    \n",
    "with open(load_dir2, 'rb') as f :\n",
    "    rehearsal_classes2 = pickle.load(f)\n",
    "    \n",
    "with open(load_dir3, 'rb') as f :\n",
    "    rehearsal_classes3 = pickle.load(f)\n",
    "\n",
    "\n",
    "merged_dict = {**rehearsal_classes, **rehearsal_classes1, **rehearsal_classes2, **rehearsal_classes3,}\n",
    "print(len(merged_dict.keys()))\n",
    "print(len(rehearsal_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"/data/LG/real_dataset/total_dataset/test_dir/Continaul_DETR/Rehearsal_dict/ALL_gpu_rehearsal_task_0\", 'rb') as f :\n",
    "    rehearsal_classes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times each index appears in the lists:\n",
      "1: 11\n",
      "32: 69\n",
      "10: 453\n",
      "35: 19\n",
      "44: 488\n",
      "19: 495\n",
      "24: 495\n",
      "13: 500\n",
      "16: 489\n",
      "23: 500\n",
      "21: 415\n",
      "18: 500\n",
      "33: 277\n",
      "9: 356\n",
      "8: 481\n",
      "4: 283\n",
      "25: 500\n",
      "27: 152\n",
      "11: 468\n",
      "3: 188\n",
      "6: 369\n",
      "15: 500\n",
      "14: 115\n",
      "17: 500\n",
      "5: 500\n",
      "42: 45\n",
      "20: 246\n",
      "22: 500\n",
      "7: 500\n",
      "34: 92\n",
      "2: 211\n",
      "31: 206\n",
      "28: 194\n",
      "38: 112\n",
      "39: 14\n",
      "40: 14\n",
      "41: 25\n",
      "36: 17\n",
      "37: 59\n",
      "43: 18\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "index_counts = defaultdict(int)\n",
    "\n",
    "for value in merged_dict.values():\n",
    "    for index in value[1]:\n",
    "        index_counts[index] += 1\n",
    "\n",
    "print(\"Number of times each index appears in the lists:\")\n",
    "for index, count in index_counts.items():\n",
    "    print(f\"{index}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Done Combined dataset ***********\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tt = [28, 32, 35, 41, 56]\n",
    "re = multigpu_rehearsal(\"/data/LG/real_dataset/total_dataset/test_dir/Continaul_DETR/Rehearsal_dict/\", 125, 4, 2, *tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6395"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "def multigpu_rehearsal(dir, limit_memory_size, gpu_counts, task_num,*args):\n",
    "    '''\n",
    "        limit_memory_size : args.memory\n",
    "        rehearsal_classes: Rehearsal classes\n",
    "        args : old classes (Not Now classes)\n",
    "    '''\n",
    "    limit_memory_size = limit_memory_size * gpu_counts\n",
    "    \n",
    "    dir_list = [dir + str(num) +\"_gpu_rehearsal_task_\" + str(task_num) for num in range(gpu_counts)]\n",
    "    for each_dir in dir_list:\n",
    "        if os.path.isfile(each_dir) == False:\n",
    "            raise Exception(\"No rehearsal file\")\n",
    "        \n",
    "    merge_dict = {}\n",
    "    for idx, dictionary_dir in enumerate(dir_list):\n",
    "        with open(dictionary_dir, 'rb') as f :\n",
    "            temp = pickle.load(f)\n",
    "            merge_dict = {**merge_dict, **temp}\n",
    "    \n",
    "    while True:\n",
    "        check_list = [len(list(filter(lambda x: index in x[1], list(merge_dict.values())))) for index in args]\n",
    "        #print(check_list)\n",
    "        temp_array = np.array(check_list)\n",
    "        temp_array = temp_array < limit_memory_size\n",
    "        #print(temp_array)\n",
    "        if all(temp_array) == True:\n",
    "            print(f\"********** Done Combined dataset ***********\")\n",
    "            return merge_dict\n",
    "        \n",
    "        over_list = []\n",
    "        for t, arg in zip(temp_array, args):\n",
    "            if t == False:\n",
    "                over_list.append(arg)\n",
    "                \n",
    "        check_list = list(filter(lambda x: all(item in x[1][1] for item in over_list), list(merge_dict.items())))\n",
    "        sorted_result = sorted(check_list, key = lambda x : x[1][0])\n",
    "        if len(sorted_result) == 0 :\n",
    "            check_list = list(filter(lambda x: any(item in x[1][1] for item in over_list), list(merge_dict.items())))\n",
    "            sorted_result = sorted(check_list, key = lambda x : x[1][0])\n",
    "            del merge_dict[sorted_result[-1][0]]\n",
    "            continue\n",
    "        \n",
    "        del merge_dict[sorted_result[-1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8626\n",
      "12289\n"
     ]
    }
   ],
   "source": [
    "a = {**rehearsal_classes, **rehearsal_classes1}\n",
    "b = {**a, **rehearsal_classes2}\n",
    "print(len(a))\n",
    "print(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0. 200.   0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.array([500, 700, 400])\n",
    "arr = temp - 500\n",
    "arr = np.clip(arr, 0, np.Infinity)\n",
    "print(arr)\n",
    "\n",
    "all(arr == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def _combine_rehearsal_size(limit_memory_size, rehearsal_classes, *args):\n",
    "    while True:\n",
    "        check_list = [len(list(filter(lambda x: index in x[1], list(rehearsal_classes.values())))) for index in args]\n",
    "        #print(check_list)\n",
    "        temp_array = np.array(check_list)\n",
    "        temp_array = temp_array < limit_memory_size\n",
    "        #print(temp_array)\n",
    "        if all(temp_array) == True:\n",
    "            return rehearsal_classes\n",
    "        \n",
    "        over_list = []\n",
    "        for t, arg in zip(temp_array, args):\n",
    "            if t == False:\n",
    "                over_list.append(arg)\n",
    "                \n",
    "        check_list = list(filter(lambda x: all(item in x[1][1] for item in over_list), list(rehearsal_classes.items())))\n",
    "        sorted_result = sorted(check_list, key = lambda x : x[1][0])\n",
    "        if len(sorted_result) == 0 :\n",
    "            check_list = list(filter(lambda x: any(item in x[1][1] for item in over_list), list(rehearsal_classes.items())))\n",
    "            sorted_result = sorted(check_list, key = lambda x : x[1][0])\n",
    "            del rehearsal_classes[sorted_result[-1][0]]\n",
    "            continue\n",
    "        \n",
    "        del rehearsal_classes[sorted_result[-1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_check = _combine_rehearsal_size(1000, merged_dict, *[28, 32, 35, 41, 56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14190"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "50\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "for contents in temp.values:\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.60s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "coco = COCO(\"/data/LG/real_dataset/total_dataset/didvepz/plustotal/output_json/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "526809\n"
     ]
    }
   ],
   "source": [
    "img_ids = coco.getImgIds(catIds=[1,2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "print(img_ids)\n",
    "print(len(coco.getAnnIds(imgIds=img_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.getImgIds(catIds=[1,2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43853\n"
     ]
    }
   ],
   "source": [
    "#클래스에 해당하는 이미지 불러오기\n",
    "Class_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "total_img = []\n",
    "\n",
    "for c_idx in Class_list:\n",
    "    img_ids = coco.getImgIds(catIds= c_idx)\n",
    "    total_img.extend(img_ids)\n",
    "\n",
    "unique_img = list(set(total_img))\n",
    "print(len(unique_img))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], [45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]]\n",
      "[56, 57, 58, 59]\n",
      "[45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
       " [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33],\n",
       " [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
       " [45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def DivideTask_for_incre(Task_Counts: int, Total_Classes: int):\n",
    "    classes = [idx+1 for idx in range(Total_Classes)]\n",
    "    Task = int(Total_Classes / Task_Counts)\n",
    "    Rest_Classes_num = Total_Classes % Task_Counts\n",
    "    \n",
    "    start = 0\n",
    "    end = Task\n",
    "    Divided_Classes = []\n",
    "    for _ in range(Task_Counts):\n",
    "        Divided_Classes.append(classes[start:end])\n",
    "        start += Task\n",
    "        end += Task\n",
    "    print(Divided_Classes)\n",
    "    if Rest_Classes_num != 0:\n",
    "        Rest_Classes = classes[-Rest_Classes_num:]\n",
    "        print(Rest_Classes)\n",
    "        print(Divided_Classes[-1])\n",
    "        Divided_Classes[-1].extend(Rest_Classes)\n",
    "    \n",
    "    \n",
    "    return Divided_Classes\n",
    "    \n",
    "    \n",
    "\n",
    "DivideTask_for_incre(5, 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'area': 11466,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [557, 507, 91, 126],\n",
       "  'category_id': 18,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15552},\n",
       " {'area': 11072,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [655, 459, 64, 173],\n",
       "  'category_id': 4,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15553},\n",
       " {'area': 15656,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [717, 430, 76, 206],\n",
       "  'category_id': 4,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15554},\n",
       " {'area': 30906,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [797, 486, 202, 153],\n",
       "  'category_id': 3,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15555},\n",
       " {'area': 14256,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [572, 753, 81, 176],\n",
       "  'category_id': 5,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15556},\n",
       " {'area': 12384,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [645, 795, 86, 144],\n",
       "  'category_id': 3,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15557},\n",
       " {'area': 20705,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [726, 782, 101, 205],\n",
       "  'category_id': 13,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15558},\n",
       " {'area': 13467,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [813, 752, 67, 201],\n",
       "  'category_id': 4,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15559},\n",
       " {'area': 32032,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [867, 695, 112, 286],\n",
       "  'category_id': 4,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15560}]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.loadAnns(coco.getAnnIds(unique_img[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'area': 11466,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [557, 507, 91, 126],\n",
       "  'category_id': 18,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15552},\n",
       " {'area': 11072,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [655, 459, 64, 173],\n",
       "  'category_id': 4,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15553},\n",
       " {'area': 15656,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [717, 430, 76, 206],\n",
       "  'category_id': 4,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15554},\n",
       " {'area': 30906,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [797, 486, 202, 153],\n",
       "  'category_id': 3,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15555},\n",
       " {'area': 14256,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [572, 753, 81, 176],\n",
       "  'category_id': 5,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15556},\n",
       " {'area': 12384,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [645, 795, 86, 144],\n",
       "  'category_id': 3,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15557},\n",
       " {'area': 20705,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [726, 782, 101, 205],\n",
       "  'category_id': 13,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15558},\n",
       " {'area': 13467,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [813, 752, 67, 201],\n",
       "  'category_id': 4,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15559},\n",
       " {'area': 32032,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [867, 695, 112, 286],\n",
       "  'category_id': 4,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 4423,\n",
       "  'id': 15560}]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.loadAnns(coco.getAnnIds(unique_img[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "9\n",
      "[{'area': 11072, 'iscrowd': 0, 'bbox': [655, 459, 64, 173], 'category_id': 4, 'ignore': 0, 'segmentation': [], 'image_id': 4423, 'id': 15553}, {'area': 15656, 'iscrowd': 0, 'bbox': [717, 430, 76, 206], 'category_id': 4, 'ignore': 0, 'segmentation': [], 'image_id': 4423, 'id': 15554}, {'area': 30906, 'iscrowd': 0, 'bbox': [797, 486, 202, 153], 'category_id': 3, 'ignore': 0, 'segmentation': [], 'image_id': 4423, 'id': 15555}, {'area': 14256, 'iscrowd': 0, 'bbox': [572, 753, 81, 176], 'category_id': 5, 'ignore': 0, 'segmentation': [], 'image_id': 4423, 'id': 15556}, {'area': 12384, 'iscrowd': 0, 'bbox': [645, 795, 86, 144], 'category_id': 3, 'ignore': 0, 'segmentation': [], 'image_id': 4423, 'id': 15557}, {'area': 13467, 'iscrowd': 0, 'bbox': [813, 752, 67, 201], 'category_id': 4, 'ignore': 0, 'segmentation': [], 'image_id': 4423, 'id': 15559}, {'area': 32032, 'iscrowd': 0, 'bbox': [867, 695, 112, 286], 'category_id': 4, 'ignore': 0, 'segmentation': [], 'image_id': 4423, 'id': 15560}]\n"
     ]
    }
   ],
   "source": [
    "a = [ value for value in coco.loadAnns(coco.getAnnIds(unique_img[0])) if value[\"category_id\"] in Class_list]\n",
    "b = [ value for value in coco.loadAnns(coco.getAnnIds(unique_img[0])) ]\n",
    "\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation id : 17057\n",
      "[{'area': 21855, 'iscrowd': 0, 'bbox': [995, 700, 93, 235], 'category_id': 1, 'ignore': 0, 'segmentation': [], 'image_id': 4668, 'id': 17057}]\n"
     ]
    }
   ],
   "source": [
    "ann_id = coco.getAnnIds(catIds=1)\n",
    "\n",
    "print(f\"annotation id : {ann_id[0]}\")\n",
    "print(coco.loadAnns(ann_id[0]))\n",
    "\n",
    "coco.getCatIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'area': 8687,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [157, 56, 73, 119],\n",
       "  'category_id': 37,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 100,\n",
       "  'id': 368},\n",
       " {'area': 12393,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [221, 32, 81, 153],\n",
       "  'category_id': 37,\n",
       "  'ignore': 0,\n",
       "  'segmentation': [],\n",
       "  'image_id': 100,\n",
       "  'id': 369}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.loadAnns(coco.getAnnIds(100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deformable_detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5a09c2b6f34fcc5c33c974bbe101725cfa8cb2fd6eedfde5515bd07ecae16c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
